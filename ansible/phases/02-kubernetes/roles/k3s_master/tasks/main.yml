---
# K3S MASTER NODE SETUP
# Install k3s server on master node and generate token for worker/edge

- name: "Install required packages (no containerd - k3s manages it)"
  apt:
    name: [curl, wget]
    state: present
    update_cache: no
  tags:
    - install
    - packages

- name: "Check if k3s is already installed"
  stat:
    path: "{{ k3s_install_dir }}/k3s"
  register: k3s_installed
  tags:
    - install
    - k3s

- name: "Stop existing k3s service if running (cleanup before reinstall)"
  systemd:
    name: "{{ k3s_service_name }}"
    state: stopped
  ignore_errors: yes
  when: k3s_installed.stat.exists
  tags:
    - cleanup
    - k3s

- name: "Remove existing k3s installation (cleanup before reinstall)"
  shell: |
    if [ -f /usr/local/bin/k3s-uninstall.sh ]; then
      /usr/local/bin/k3s-uninstall.sh
    else
      echo "k3s uninstall script not found, skipping cleanup"
    fi
  ignore_errors: yes
  when: k3s_installed.stat.exists
  tags:
    - cleanup
    - k3s

- name: "Create k3s configuration directory"
  file:
    path: "{{ k3s_config_dir }}"
    state: directory
    mode: "0755"
    owner: root
    group: root
  tags:
    - configure
    - k3s

- name: "Detect host interface that matches ansible_host (for flannel-iface)"
  shell: |
    ip -4 -o addr show | awk -v IP="{{ ansible_host }}" '$4 ~ IP {print $2; exit}'
  register: k3s_flannel_iface_guess
  changed_when: false
  tags:
    - configure
    - k3s

- name: "Set flannel iface fact"
  set_fact:
    k3s_flannel_iface: "{{ k3s_flannel_iface_guess.stdout | trim }}"
  tags:
    - configure
    - k3s

- name: "Generate k3s cluster token"
  shell: openssl rand -hex 32
  register: k3s_cluster_token
  changed_when: false
  tags:
    - configure
    - k3s

- name: "Create k3s configuration file with proper network settings"
  copy:
    content: |
      cluster-cidr: "10.42.0.0/16"
      service-cidr: "10.43.0.0/16"
      flannel-backend: "vxlan"
      bind-address: "{{ k3s_bind_address }}"
      advertise-address: "{{ k3s_advertise_address }}"
      node-ip: "{{ k3s_node_ip }}"
      flannel-iface: "{{ k3s_flannel_iface | default('') }}"
      token: "{{ k3s_cluster_token.stdout }}"
      disable:
        - traefik
        - servicelb
        - cloud-controller
        - network-policy
        - local-storage
    dest: "{{ k3s_config_dir }}/config.yaml"
    mode: "0644"
    owner: root
    group: root
  tags:
    - configure
    - k3s

- name: "Download and install k3s server"
  shell: |
    curl -sfL {{ k3s_install_url }} | {{ ('INSTALL_K3S_VERSION=' ~ k3s_version ~ ' ') if (k3s_version | default('')) | length > 0 else '' }}INSTALL_K3S_CHANNEL={{ k3s_channel }} sh -
  args:
    creates: "{{ k3s_install_dir }}/k3s"
  tags:
    - configure
    - k3s

- name: "Wait for k3s server to be ready"
  shell: |
    echo "â³ Initializing k3s server..."
    for i in $(seq {{ k3s_startup_timeout // 5 }}); do
      echo -n "."
      if systemctl is-active --quiet {{ k3s_service_name }}; then
        echo ""
        echo "âœ… k3s service active (${i}s)"
        echo "â³ Checking k3s API server..."
        for j in $(seq {{ k3s_api_timeout // 5 }}); do
          echo -n "."
          if kubectl get nodes --no-headers 2>/dev/null | grep -q "master"; then
            echo ""
            echo "âœ… k3s API server is ready (${j}s)"
            exit 0
          fi
          sleep 5
        done
        echo ""
        echo "âŒ API server not responding"
        kubectl get nodes 2>&1 || true
        exit 1
      fi
      sleep 5
    done
    echo ""
    echo "âŒ k3s not started within {{ k3s_startup_timeout }}s"
    systemctl status {{ k3s_service_name }} --no-pager
    exit 1
  register: k3s_ready
  failed_when: k3s_ready.rc != 0
  tags:
    - configure
    - k3s

- name: "Get k3s join token for worker/edge nodes"
  shell: cat /var/lib/rancher/k3s/server/node-token
  register: k3s_token
  changed_when: false
  tags:
    - setup
    - tokens

- name: "Create k3s join token file for distribution"
  copy:
    content: "{{ k3s_token.stdout }}"
    dest: "{{ k3s_token_path }}"
    owner: vagrant
    group: vagrant
    mode: "0600"
  tags:
    - setup
    - tokens

- name: "Copy kubeconfig for cluster access"
  copy:
    src: "{{ k3s_config_dir }}/k3s.yaml"
    dest: "{{ kubeconfig_path }}"
    owner: vagrant
    group: vagrant
    mode: "0600"
    remote_src: true
  tags:
    - setup
    - kubeconfig

- name: "Install kubectl CLI tool"
  shell: |
    curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    chmod +x kubectl
    sudo mv kubectl {{ kubectl_install_path }}
  args:
    creates: "{{ kubectl_install_path }}"
  tags:
    - setup
    - kubectl

- name: "Label master node with tier=master"
  shell: kubectl label node master tier=master --overwrite
  args:
    creates: /tmp/master_labeled
  tags:
    - setup
    - labels

- name: "Restart k3s to apply new configuration"
  systemd:
    name: k3s
    state: restarted
  tags:
    - setup
    - flannel
    - restart

- name: "Wait for k3s to be ready after restart"
  shell: |
    echo "â³ Waiting for k3s to be ready after restart..."
    for i in $(seq 30); do
      if systemctl is-active --quiet k3s; then
        echo "âœ… k3s is running (${i}s)"
        exit 0
      fi
      echo -n "."
      sleep 2
    done
    echo "âŒ k3s not ready after 60s"
    exit 1
  register: k3s_restart_wait
  failed_when: k3s_restart_wait.rc != 0
  tags:
    - setup
    - flannel
    - restart

- name: "Wait for Flannel to be ready (with retries)"
  shell: |
    echo "â³ Waiting for Flannel to be ready..."
    for i in $(seq 30); do
      echo -n "."
      if ip addr show cni0 >/dev/null 2>&1; then
        if ip addr show flannel.1 >/dev/null 2>&1 || [ -f /run/flannel/subnet.env ]; then
          echo ""
          echo "âœ… Flannel interfaces ready (${i}s)"
          exit 0
        fi
      fi
      sleep 2
    done
    echo ""
    echo "âŒ Flannel not ready after 60s"
    exit 1
  register: flannel_wait
  failed_when: flannel_wait.rc != 0
  tags:
    - setup
    - flannel
    - wait

- name: "Verify Flannel configuration is correct"
  shell: |
    echo "ğŸ” Verifying Flannel configuration..."

    # Check if flannel.1 interface exists
    if ip addr show flannel.1 >/dev/null 2>&1; then
      echo "âœ… flannel.1 interface exists"
      ip addr show flannel.1
    else
      echo "âŒ flannel.1 interface not found"
      exit 1
    fi

    # Check if cni0 interface exists with correct subnet
    if ip addr show cni0 | grep -q "10.42.0.1/24"; then
      echo "âœ… cni0 interface has correct subnet"
    else
      echo "âŒ cni0 interface has incorrect subnet"
      ip addr show cni0 || true
      exit 1
    fi

    # Check if subnet.env exists and is correct
    if [ -f /run/flannel/subnet.env ]; then
      echo "âœ… Flannel subnet.env exists"
      cat /run/flannel/subnet.env
      if grep -q "FLANNEL_NETWORK=10.42.0.0/16" /run/flannel/subnet.env; then
        echo "âœ… Flannel subnet.env has correct network"
      else
        echo "âŒ Flannel subnet.env has incorrect network"
        exit 1
      fi
    else
      echo "âŒ Flannel subnet.env missing"
      exit 1
    fi

    # Check routing table has correct routes
    if ip route | grep -q "10.42.0.0/24 dev cni0"; then
      echo "âœ… Routing table has correct Flannel routes"
    else
      echo "âŒ Routing table missing Flannel routes"
      ip route | grep -E "10\.42|flannel" || true
      exit 1
    fi

    echo "âœ… Flannel configuration verified successfully"
  register: flannel_verify
  failed_when: flannel_verify.rc != 0
  tags:
    - setup
    - flannel
    - verification
